{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - try bigram\n",
    " - [x] use pretraining embeddings\n",
    " - _! BUG ! different batch sizes will end up with different acc score in testing, inconsistent acc for different batch size_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(input_path, 'dev_text.txt'), 'r', encoding='utf-8') as f:\n",
    "#     dev_text = f.read().strip().split('\\n')\n",
    "\n",
    "# with open(os.path.join(input_path, 'heldout_text.txt'), 'r', encoding='utf-8') as f:\n",
    "#     heldout_text = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_label_path = os.path.join(input_path,'dev_label.txt')\n",
    "# with open(dev_label_path, 'r', encoding='utf-8') as f:\n",
    "#     dev_y = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data = pd.DataFrame({'text':dev_text, 'label':dev_y})\n",
    "\n",
    "# dev_data.to_csv(os.path.join(input_path, 'dev_data.tsv'), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.DataFrame({'text':heldout_text})\n",
    "# test_data.to_csv(os.path.join(input_path, 'test_data.tsv'), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "import baseline_lstm_model\n",
    "import oh_lstm_model\n",
    "import fasttext_model\n",
    "import residual_lstm_model\n",
    "import config\n",
    "import util\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_packages = [paths, baseline_lstm_model, fasttext_model, oh_lstm_model,residual_lstm_model, util, config]\n",
    "for package in reload_packages:\n",
    "    importlib.reload(package)\n",
    "# importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import random\n",
    "from torchtext.data import TabularDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "def tokenizer(string): \n",
    "    return [word.text.lower() for word in nlp(clean(string))]\n",
    "\n",
    "def clean(text):\n",
    "    '''remove non alphanumeric character, remove links'''\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub(r'https?:/\\/\\S+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize = tokenizer, include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_datafields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "dev_dataset = TabularDataset(\n",
    "               path=os.path.join(paths.input_path, 'dev_data.tsv'),\n",
    "               format='tsv',\n",
    "               skip_header=True,\n",
    "               fields=dev_datafields)\n",
    "\n",
    "test_datafields = [(\"text\", TEXT)]\n",
    "test_dataset = TabularDataset(\n",
    "           path=os.path.join(paths.input_path, 'test_data.tsv'),\n",
    "           format='csv',\n",
    "           skip_header=True,\n",
    "           fields=test_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = dev_dataset.split(split_ratio=0.85, random_state = random.seed(SEED), stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_dataset, \n",
    "                 max_size = 40000, \n",
    "                 vectors = \"glove.840B.300d\",\n",
    "                 unk_init = torch.Tensor.normal_ # initialize unk and pad with normal distribution\n",
    "                )\n",
    "LABEL.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1245, -2.0167, -1.8408, -1.8693,  0.5336, -1.1077, -2.1604,  0.2489,\n",
       "        -0.2139, -1.4939,  0.5098,  0.1470,  1.7412,  0.4003,  0.0142,  0.2372,\n",
       "         0.1753,  0.5593,  1.4649,  0.1637, -1.5092, -1.2597, -0.4065, -2.4065,\n",
       "        -1.0229, -0.5841, -0.1961,  0.7232,  0.7993, -0.5898,  0.8280,  1.9995,\n",
       "        -1.6778, -0.6556, -2.1492, -0.5696, -0.9129,  1.7062, -0.9049, -0.2820,\n",
       "         0.9540, -1.3509,  0.1597,  0.7766,  0.9011, -0.6364, -0.0637, -0.2093,\n",
       "        -0.7578,  2.4950, -0.1423, -1.1769,  0.4894, -1.6177,  0.9247, -0.9170,\n",
       "        -0.0758,  0.0505, -0.4633, -0.2515,  0.8401, -1.2632,  0.7737, -1.4244,\n",
       "         1.1296,  0.4472, -1.2549, -2.6256, -0.0140, -0.4426, -0.4629,  0.4480,\n",
       "        -0.5305,  1.5050, -0.0608, -2.0750,  1.3199, -0.8722,  0.9296,  0.7483,\n",
       "        -0.0807, -0.1050, -2.5114, -0.9549,  1.6605,  0.2417, -1.5093, -1.1866,\n",
       "         1.1405,  0.5623, -1.0970, -0.3976,  1.0002, -0.3124, -1.0867,  0.3114,\n",
       "         1.5388, -0.6063,  0.1500,  0.1554,  1.9340, -1.2906, -1.1106, -0.6640,\n",
       "         0.5706,  1.1938,  0.6604, -0.9165, -1.3304, -0.3389, -0.1064, -0.6270,\n",
       "        -0.5846, -1.0228,  0.6979,  1.5253,  1.2404, -0.7859,  0.8831, -0.0897,\n",
       "         0.2584, -1.3919,  0.6408,  0.0263,  0.0779, -0.6720, -0.3113,  0.5496,\n",
       "        -0.2619, -0.8582, -0.1248, -0.5221, -0.3194,  0.3769, -0.9085, -2.6133,\n",
       "        -0.8636,  0.5815, -0.9000,  1.1638, -0.8887,  0.3952, -2.6537,  0.8225,\n",
       "         0.2920, -2.0415,  1.7532, -1.4339, -0.9450,  0.9038, -0.0510, -0.2629,\n",
       "         1.6592, -0.3990, -0.2492,  0.6547,  1.5550,  0.5550,  0.0399,  0.9979,\n",
       "         1.3258,  0.7210,  0.0932, -1.1069, -1.3662, -1.6655,  2.4047, -0.2949,\n",
       "         0.8774,  0.5297,  0.5686, -0.8252,  0.6196,  0.6617, -1.7568,  0.5895,\n",
       "         1.3411,  1.3972, -0.1749,  0.7804, -0.9937, -0.7437,  0.0207,  0.6231,\n",
       "        -1.1134,  1.3519, -1.0353, -1.3270,  0.8429,  0.1978, -0.0627, -0.5825,\n",
       "        -0.4486, -0.0270,  1.4552,  0.8442,  0.6284,  0.9726,  0.6593, -0.3102,\n",
       "         0.8510,  0.9531,  1.7390,  0.1035,  0.8017,  1.2041,  0.4557, -1.3810,\n",
       "         0.2246,  0.7176,  0.2869, -0.2386, -1.1154, -0.9341, -0.9757,  0.1790,\n",
       "         0.1249,  1.1088, -0.7070, -0.0449,  0.7549,  1.5986, -0.5815,  0.4211,\n",
       "        -0.2801,  0.1246,  0.1093,  0.0431, -0.9403,  0.9225, -0.9477,  2.2438,\n",
       "         0.2420,  0.0904, -0.0899,  0.8034,  1.5299,  1.1883,  0.2111,  0.3516,\n",
       "        -0.1341, -1.5026,  0.2739, -1.8866,  0.0506, -0.4909,  0.5277, -1.1579,\n",
       "         1.8764, -0.1114,  0.6446,  1.6038, -1.0081,  0.5998,  0.8196, -1.1297,\n",
       "         1.4658,  0.7166,  1.1139, -0.3828, -1.6467, -0.7202,  0.0934,  0.7659,\n",
       "         1.0555, -0.2734, -0.6298,  1.6699, -1.3788, -0.5098,  0.9971,  2.8279,\n",
       "        -0.6816,  1.2269, -0.3459, -0.4880, -0.3180,  0.3859,  1.7322, -0.4960,\n",
       "         1.0544, -0.3220,  0.9706, -0.8702,  0.9023,  2.0541, -0.1230,  1.0293,\n",
       "         0.7759, -1.1892, -0.1832,  2.0059, -0.9922, -0.9702,  1.1093, -1.0466,\n",
       "        -1.3074, -1.9087,  2.6203, -0.5614])"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['<unk>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset), \n",
    "    batch_size = 1,\n",
    "    device = device,\n",
    "    sort = False, # whether sort the whole dataset with sortkey\n",
    "    shuffle = True,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True, #sort by length for padding\n",
    "    repeat = False)\n",
    "\n",
    "test_iterator = data.Iterator(\n",
    "    test_dataset,\n",
    "    batch_size = 1,\n",
    "    device = device, \n",
    "    sort = False, \n",
    "    shuffle = False,\n",
    "    train = False,\n",
    "#     sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = False, # don't wanna sort in testing set\n",
    "    repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'very', 'well', 'made', 'film']"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 22332), ('and', 10907), ('a', 10771)]"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f51a3985ae8>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.AdaptiveAvgPool2d((1,None))\n",
    "# input = torch.randn(123, 2, 256).permute(1,0,2)\n",
    "# output = m(input).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = baseline_lstm_model.BaselineLstm(vocab_size=len(TEXT.vocab), \n",
    "#                                             embed_size=300, \n",
    "#                                             hidden_size=32, \n",
    "#                                             output_dim=1,\n",
    "#                                             nlayers=1,\n",
    "#                                             bidirectional=True,\n",
    "#                                             lstm_dropout=0,\n",
    "#                                             dropout=0.6,\n",
    "#                                             pad_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "#                                             train_embedding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = oh_lstm_model.OhLstm(vocab_size=len(TEXT.vocab), \n",
    "#                                             embed_size=300, \n",
    "#                                             hidden_size=32, \n",
    "#                                             output_dim=1,\n",
    "#                                             nlayers=1,\n",
    "#                                             bidirectional=True,\n",
    "#                                             lstm_dropout=0,\n",
    "#                                             dropout=0.4,\n",
    "#                                             pad_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "#                                             train_embedding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = fasttext_model.Fasttext(vocab_size=len(TEXT.vocab), \n",
    "#                                             embed_size=300,\n",
    "#                                             output_dim=1,\n",
    "#                                             dropout1=0.2,\n",
    "#                                             dropout2=0.1,\n",
    "#                                             pad_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "#                                             train_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = residual_lstm_model.ResidualLstm(vocab_size=len(TEXT.vocab), \n",
    "                                                embed_size=300, \n",
    "                                                hidden_size=32, \n",
    "                                                output_dim=1,\n",
    "                                                nlayers=1,\n",
    "                                                bidirectional=True,\n",
    "                                                lstm_dropout=0,\n",
    "                                                dropout1=0.0,\n",
    "                                                dropout2=0.3,\n",
    "                                                dropout3=0.5,\n",
    "                                                pad_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "                                                train_embedding=False)\n",
    "# 02/04 -> 8975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualLstm(\n",
       "  (embedding): Embedding(23168, 300, padding_idx=1)\n",
       "  (lstm): LSTM(300, 32, bidirectional=True)\n",
       "  (fc): Linear(in_features=364, out_features=1, bias=True)\n",
       "  (globalpooling): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "  (dropout1): Dropout(p=0.0)\n",
       "  (dropout2): Dropout(p=0.3)\n",
       "  (dropout3): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1245, -2.0167, -1.8408,  ..., -1.9087,  2.6203, -0.5614],\n",
       "        [ 0.1405,  2.6338,  1.4239,  ..., -2.4909,  0.6555, -0.9523],\n",
       "        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n",
       "        ...,\n",
       "        [ 0.2548, -0.1572,  0.6147,  ...,  0.2006, -0.3907, -0.3322],\n",
       "        [ 0.1896,  0.1672,  0.3407,  ..., -0.3786, -0.0278, -0.1949],\n",
       "        [ 0.3195,  0.2435, -0.1777,  ..., -0.0243, -0.6011,  0.2368]])"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "# load embedding\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "# # init unk token\n",
    "# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "# model.embedding.weight.data[UNK_IDX] = torch.zeros(200)\n",
    "# model.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-03)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_epoch, best_vali_loss, starting_epoch = 0, 400, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Epoch     0 \n",
      "Epoch: 0\tBatch: 200\tAvg-Loss: 0.6958\tAvg-Acc: 0.5500 \n",
      "Epoch: 0\tBatch: 400\tAvg-Loss: 0.6750\tAvg-Acc: 0.5400 \n",
      "Epoch: 0\tBatch: 600\tAvg-Loss: 0.6516\tAvg-Acc: 0.6250 \n",
      "Epoch: 0\tBatch: 800\tAvg-Loss: 0.5503\tAvg-Acc: 0.7350 \n",
      "Epoch: 0\tBatch: 1000\tAvg-Loss: 0.5353\tAvg-Acc: 0.7400 \n",
      "Epoch: 0\tBatch: 1200\tAvg-Loss: 0.4539\tAvg-Acc: 0.8250 \n",
      "Epoch: 0\tBatch: 1400\tAvg-Loss: 0.4628\tAvg-Acc: 0.8400 \n",
      "Epoch: 0\tBatch: 1600\tAvg-Loss: 0.4740\tAvg-Acc: 0.7950 \n",
      "Train Loss: 0.4165\tTrain Acc: 0.8135\tVal Loss: 0.4327\tVal Acc: 0.8100 \n",
      "Epoch time used:  109.40562725067139 s \n",
      "### Epoch     1 \n",
      "Epoch: 1\tBatch: 200\tAvg-Loss: 0.3746\tAvg-Acc: 0.8700 \n",
      "Epoch: 1\tBatch: 400\tAvg-Loss: 0.3294\tAvg-Acc: 0.8450 \n",
      "Epoch: 1\tBatch: 600\tAvg-Loss: 0.3617\tAvg-Acc: 0.8400 \n",
      "Epoch: 1\tBatch: 800\tAvg-Loss: 0.4400\tAvg-Acc: 0.8250 \n",
      "Epoch: 1\tBatch: 1000\tAvg-Loss: 0.3985\tAvg-Acc: 0.8200 \n",
      "Epoch: 1\tBatch: 1200\tAvg-Loss: 0.3571\tAvg-Acc: 0.8150 \n",
      "Epoch: 1\tBatch: 1400\tAvg-Loss: 0.3920\tAvg-Acc: 0.8500 \n",
      "Epoch: 1\tBatch: 1600\tAvg-Loss: 0.4087\tAvg-Acc: 0.8100 \n",
      "Train Loss: 0.3435\tTrain Acc: 0.8471\tVal Loss: 0.4608\tVal Acc: 0.7800 \n",
      "Epoch time used:  109.59803652763367 s \n",
      "### Epoch     2 \n",
      "Epoch: 2\tBatch: 200\tAvg-Loss: 0.2625\tAvg-Acc: 0.9150 \n",
      "Epoch: 2\tBatch: 400\tAvg-Loss: 0.3600\tAvg-Acc: 0.8350 \n",
      "Epoch: 2\tBatch: 600\tAvg-Loss: 0.3537\tAvg-Acc: 0.8750 \n",
      "Epoch: 2\tBatch: 800\tAvg-Loss: 0.2682\tAvg-Acc: 0.8950 \n",
      "Epoch: 2\tBatch: 1000\tAvg-Loss: 0.3219\tAvg-Acc: 0.8900 \n",
      "Epoch: 2\tBatch: 1200\tAvg-Loss: 0.2804\tAvg-Acc: 0.8900 \n",
      "Epoch: 2\tBatch: 1400\tAvg-Loss: 0.3105\tAvg-Acc: 0.8600 \n",
      "Epoch: 2\tBatch: 1600\tAvg-Loss: 0.3130\tAvg-Acc: 0.8850 \n",
      "Train Loss: 0.2343\tTrain Acc: 0.9200\tVal Loss: 0.3141\tVal Acc: 0.8733 \n",
      "Epoch time used:  109.9619619846344 s \n",
      "### Epoch     3 \n",
      "Epoch: 3\tBatch: 200\tAvg-Loss: 0.2212\tAvg-Acc: 0.9300 \n",
      "Epoch: 3\tBatch: 400\tAvg-Loss: 0.2790\tAvg-Acc: 0.8950 \n",
      "Epoch: 3\tBatch: 600\tAvg-Loss: 0.1999\tAvg-Acc: 0.9400 \n",
      "Epoch: 3\tBatch: 800\tAvg-Loss: 0.2628\tAvg-Acc: 0.9050 \n",
      "Epoch: 3\tBatch: 1000\tAvg-Loss: 0.3119\tAvg-Acc: 0.8750 \n",
      "Epoch: 3\tBatch: 1200\tAvg-Loss: 0.3142\tAvg-Acc: 0.8900 \n",
      "Epoch: 3\tBatch: 1400\tAvg-Loss: 0.2805\tAvg-Acc: 0.9200 \n",
      "Epoch: 3\tBatch: 1600\tAvg-Loss: 0.2517\tAvg-Acc: 0.8950 \n",
      "Train Loss: 0.2045\tTrain Acc: 0.9371\tVal Loss: 0.3219\tVal Acc: 0.8667 \n",
      "Epoch time used:  110.73313236236572 s \n",
      "### Epoch     4 \n",
      "Epoch: 4\tBatch: 200\tAvg-Loss: 0.3119\tAvg-Acc: 0.8900 \n",
      "Epoch: 4\tBatch: 400\tAvg-Loss: 0.1857\tAvg-Acc: 0.9350 \n",
      "Epoch: 4\tBatch: 600\tAvg-Loss: 0.2137\tAvg-Acc: 0.9150 \n",
      "Epoch: 4\tBatch: 800\tAvg-Loss: 0.1863\tAvg-Acc: 0.9400 \n",
      "Epoch: 4\tBatch: 1000\tAvg-Loss: 0.1972\tAvg-Acc: 0.9350 \n",
      "Epoch: 4\tBatch: 1200\tAvg-Loss: 0.1684\tAvg-Acc: 0.9450 \n",
      "Epoch: 4\tBatch: 1400\tAvg-Loss: 0.2148\tAvg-Acc: 0.9300 \n",
      "Epoch: 4\tBatch: 1600\tAvg-Loss: 0.1772\tAvg-Acc: 0.9550 \n",
      "Train Loss: 0.1237\tTrain Acc: 0.9641\tVal Loss: 0.3556\tVal Acc: 0.8667 \n",
      "Epoch time used:  109.54046964645386 s \n",
      "### Epoch     5 \n",
      "Epoch: 5\tBatch: 200\tAvg-Loss: 0.1359\tAvg-Acc: 0.9450 \n",
      "Epoch: 5\tBatch: 400\tAvg-Loss: 0.1036\tAvg-Acc: 0.9700 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-861-7369780636f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mDEVICE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarting_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                        model_prefix='residual_lstm_') #residual_lstm_\n\u001b[0m",
      "\u001b[0;32m~/torchtext-sentiment-analysis/src/residual_lstm_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, optimizer, criterion, train_dataloader, valid_dataloader, best_epoch, best_vali_loss, DEVICE, start_epoch, model_prefix)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mavg_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "residual_lstm_model.run(model, \n",
    "                        optimizer, \n",
    "                        criterion, \n",
    "                        train_iterator, \n",
    "                        valid_iterator, \n",
    "                        best_epoch=best_epoch,\n",
    "                        best_vali_loss=best_vali_loss, \n",
    "                        DEVICE=device, \n",
    "                        start_epoch=starting_epoch,\n",
    "                       model_prefix='residual_lstm_') #residual_lstm_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../outputs/residual_lstm_1.pth.tar'\n",
      "=> loaded checkpoint '../outputs/residual_lstm_1.pth.tar' (epoch 1)\n",
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "=> loading checkpoint '../outputs/residual_lstm_4.pth.tar'\n",
      "=> loaded checkpoint '../outputs/residual_lstm_4.pth.tar' (epoch 4)\n",
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "for epoch in [1, 4]:\n",
    "    # checkpoint = torch.load(\"checkpoint.pt\")\n",
    "    model_prediction = residual_lstm_model.ResidualLstm(vocab_size=len(TEXT.vocab), \n",
    "                                                embed_size=300, \n",
    "                                                hidden_size=32, \n",
    "                                                output_dim=1,\n",
    "                                                nlayers=1,\n",
    "                                                bidirectional=True,\n",
    "                                                lstm_dropout=0,\n",
    "                                                dropout1=0.0,\n",
    "                                                dropout2=0.3,\n",
    "                                                dropout3=0.3,\n",
    "                                                pad_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "                                                train_embedding=False)\n",
    "#     model_prediction = oh_lstm_model.OhLstm(vocab_size=22557, \n",
    "#                                             embed_size=300, \n",
    "#                                             hidden_size=64, \n",
    "#                                             output_dim=1,\n",
    "#                                             nlayers=1,\n",
    "#                                             bidirectional=True,\n",
    "#                                             lstm_dropout=0,\n",
    "#                                             dropout=0.4,\n",
    "#                                             pad_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "#                                             train_embedding=False)\n",
    "    # proceeding from old models\n",
    "    model_path = os.path.join(paths.output_path, 'residual_lstm_'+str(epoch)+'.pth.tar')\n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    starting_epoch = checkpoint['epoch']\n",
    "    # best_vali_acc = checkpoint['best_vali_acc']\n",
    "    val_loss: checkpoint['val_loss']\n",
    "    val_acc: checkpoint['val_acc']\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "    model_prediction.load_state_dict(model_state_dict)\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    best_vali_loss = checkpoint['best_vali_loss']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "          .format(model_path, checkpoint['epoch']))\n",
    "    # del checkpoint, model_state_dict\n",
    "\n",
    "    best_epoch\n",
    "\n",
    "    model_prediction.cuda()\n",
    "\n",
    "    prediction = residual_lstm_model.predict(model_prediction, test_iterator, device)\n",
    "    prediction_itos = [LABEL.vocab.itos[int(idx)] for idx in prediction]\n",
    "\n",
    "    with open(os.path.join(paths.output_path, 'heldout_pred_nn_'+'residual_lstm_'+str(epoch)+'.txt'), 'w', encoding='utf-8') as f:\n",
    "        [f.write(prediction_string+'\\n') for prediction_string in prediction_itos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_itos = [LABEL.vocab.itos[int(idx)] for idx in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(paths.output_path, 'heldout_pred_nn_val89.txt'), 'w', encoding='utf-8') as f:\n",
    "#     [f.write(prediction_string+'\\n') for prediction_string in prediction_itos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(paths.output_path, 'heldout_pred_nn_'+'fasttext_'+str(3)+'.txt'), 'r', encoding='utf-8') as f:\n",
    "    test1 = f.read().strip().split('\\n')\n",
    "with open(os.path.join(paths.output_path, 'heldout_pred_nn_'+'residual_lstm_'+str(13)+'_1.txt'), 'r', encoding='utf-8') as f:\n",
    "    test2 = f.read().strip().split('\\n')\n",
    "with open(os.path.join('..','dev_label.txt'), 'r', encoding='utf-8') as f:\n",
    "    test3 = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.807"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([a==b for a, b in zip(test1, test3)])/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_lines_for_test(seq_list, lens):\n",
    "        inputs = seq_list.permute(1,0).cpu().numpy()\n",
    "    #     lens = [len(seq) for seq in inputs]\n",
    "        # sort by length\n",
    "        seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "        ordered_inputs = torch.tensor([inputs[i] for i in seq_order]).permute(1,0).cuda()\n",
    "        ordered_seq_lens = torch.tensor([lens[i] for i in seq_order]).cuda()\n",
    "        reverse_order = sorted(range(len(lens)), key=seq_order.__getitem__, reverse=False)\n",
    "        return ordered_inputs, ordered_seq_lens, reverse_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_inputs, original_lengths = next(iter(test_iterator)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   11,   105,    12,    16,     8,     7,    80,    21,    13,  6550,\n",
       "           589,     3,  1641,  6608,    20,  5757,   492,  1088,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1],\n",
       "        [  447,     5,     2,  1214,  6336,     7,     4,    62,    75,    16,\n",
       "             2,   825,    15,   150,    52,    19,     2,   455,  3297,    15,\n",
       "            44,   332,    11,  3493,     2,   918,    60,    31,   579,    70,\n",
       "            64,    20,    12,  1148,   309,     5,  9092,     8,    74,   404,\n",
       "            50,  1694,  3603,   227,    50,   141,   447,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1],\n",
       "        [  325,    17,     2,  2031,   830,    15,   181,   387,     3,     2,\n",
       "           198,    13,     2,  4374,    10,     2,   342,   801,   195,     8,\n",
       "            15,    44,   606,    11,   158,    22,    31,    76,  1293,    54,\n",
       "          2921,    12,    21,     9,     9,    19,  4397,     6,     2,   636,\n",
       "            11,   458,     8,     4,   179,    12,     7,     4,  1132,    16,\n",
       "             8,   158,    22,   421,     6,  2682,    24,    73,    11,   458,\n",
       "             8,    40,     2,   469,  2552,  2240,   413,     4,    80,   211,\n",
       "            17,     2,   496,   110,    11,   102,   635,   292,    40,    27,\n",
       "           670,  3402,    10,    27,    94,     9,     9,    42,    14,    25,\n",
       "             4,   179,     5, 11376,   653,    45,   133,    39,    13,    19,\n",
       "            42,    28,    50,   256,   675,   131,     3,   455,    12,     7,\n",
       "             4,    55,   703,     3,    55,   755,     6,   104,    21,     9,\n",
       "             9,    55,  1151, 20304],\n",
       "        [  744,  2892,    14,  2836,     3, 15413,  1170,   199,    24,  1208,\n",
       "          1731,  2912,   171,    20,     4,  1930,     5,  1135,   774,    14,\n",
       "            43,  6215,   686,   588,  2395,     2,   311,     7,     4,  4041,\n",
       "           778,    20,   306,  3182,     3,     4,     0,   919,     0,  1998,\n",
       "          3086,    40,    66,    28, 13061,     2,    82,  2871,     0,  4126,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_inputs.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs, ordered_seq_lengths, reverse_order = collate_lines_for_test(original_inputs, original_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(test_inputs.permute(1,0)[reverse_order].permute(1,0),original_inputs).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ordered_seq_lengths[reverse_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 18,  47, 124,  50], device='cuda:0')"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 18,  47, 124,  50], device='cuda:0')"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([124,  50,  47,  18], device='cuda:0')"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
